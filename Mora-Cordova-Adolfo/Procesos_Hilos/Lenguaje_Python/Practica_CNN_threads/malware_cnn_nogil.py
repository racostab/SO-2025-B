import torch
import torch.nn as nn
import torch.optim as optim
import cv2  # OpenCV para la carga RÁPIDA de imágenes
import glob
import os
import random
import time
import sys
from concurrent.futures import ThreadPoolExecutor

# --- Parámetros de Configuración ---
DATA_PATH = "/home/adolfo/Imágenes/malevis_train_val_224x224/train/" 

IMAGE_SIZE = 224  # Tamaño de imagen (actualizado)
BATCH_SIZE = 32   # Reducido para imágenes de 224x224 (evita OOM en GPU)
NUM_EPOCHS = 10
# Usar todos los núcleos de CPU disponibles para la carga
NUM_WORKERS = os.cpu_count() or 4 

#---------------------------------------------------
# PARTE 1: EL PRE-PROCESADOR "NOGIL" CON HILOS
#---------------------------------------------------

def load_and_process_image(image_path: str) -> torch.Tensor:
    """
    Función de trabajo (worker) que ejecuta cada hilo.
    Es una tarea de CPU: leer del disco y transformar.
    
    En modo "nogil", esta función se ejecuta en paralelo real
    en múltiples núcleos de CPU.
    """
    try:
        # 1. Leer imagen del disco (CPU I/O)
        # Usamos cv2 por ser más rápido que Pillow
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        if image is None:
            # Archivo corrupto o no encontrado
            print(f"Advertencia: No se pudo leer {image_path}")
            return None
        
        # 2. Redimensionar (CPU)
        if image.shape[0] != IMAGE_SIZE or image.shape[1] != IMAGE_SIZE:
             image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)
        
        # 3. Normalizar y convertir a Tensor (CPU)
        # Normalizar píxeles a [0, 1]
        image_tensor = torch.tensor(image, dtype=torch.float32) / 255.0
        
        # Añadir dimensión de canal (ej. [224, 224] -> [1, 224, 224])
        return image_tensor.unsqueeze(0) 
    
    except Exception as e:
        print(f"Error procesando {image_path}: {e}")
        return None

def nogil_threaded_loader(file_paths: list, labels: list, batch_size: int):
    """
    Este es nuestro DataLoader "Nogil" personalizado.
    Es un generador que usa un ThreadPool para procesar lotes.
    """
    epoch_paths = list(zip(file_paths, labels))
    random.shuffle(epoch_paths)
    
    # Usamos un ThreadPoolExecutor para gestionar los hilos
    # max_workers=NUM_WORKERS le dice que use todos nuestros núcleos
    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:
        
        for i in range(0, len(epoch_paths), batch_size):
            # 1. Obtener el lote de rutas y etiquetas
            batch_data = epoch_paths[i : i + batch_size]
            batch_paths = [p for p, l in batch_data]
            batch_labels = [l for p, l in batch_data]
            
            # 2. ¡LA MAGIA NOGIL OCURRE AQUÍ!
            # executor.map() aplica 'load_and_process_image' a CADA
            # ruta en 'batch_paths' usando hilos paralelos.
            # Gracias a NOGIL, estos hilos corren en núcleos de CPU
            # separados, procesando el lote a máxima velocidad.
            
            images = list(executor.map(load_and_process_image, batch_paths))
            
            # 3. Filtrar imágenes que fallaron (None)
            valid_data = [(images[idx], batch_labels[idx]) for idx in range(len(images)) if images[idx] is not None]
            
            # Si el lote está vacío después de filtrar, saltar
            if not valid_data:
                continue
                
            # Desempaquetar los datos válidos
            valid_images, valid_labels = zip(*valid_data)
            
            # 4. Apilar en tensores
            X_batch = torch.stack(valid_images)
            y_batch = torch.tensor(valid_labels, dtype=torch.long)
            
            # 5. Entregar el lote al bucle de entrenamiento
            yield X_batch, y_batch

#---------------------------------------------------
# PARTE 2: EL MODELO CNN 
#---------------------------------------------------

class SimpleMalwareCNN(nn.Module):
    def __init__(self, num_classes):
        super(SimpleMalwareCNN, self).__init__()
        # Entrada será [Batch, 1, 224, 224]
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2) # -> [16, 112, 112]
        
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2) # -> [32, 56, 56]
        
        # --- Cálculo Aplanado ---
        # (IMAGE_SIZE / 2) / 2 = 224 / 4 = 56
        # Tamaño aplanado = 32 (canales) * 56 * 56 = 100,352
        flat_size = 32 * (IMAGE_SIZE // 4) * (IMAGE_SIZE // 4)
        
        print(f"Modelo CNN iniciado. Tamaño de capa densa: {flat_size}")
        
        self.fc1 = nn.Linear(flat_size, 128)
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        
        # Aplanar la salida para la capa densa
        x = x.view(x.size(0), -1) 
        
        x = self.relu3(self.fc1(x))
        x = self.fc2(x)
        return x

#---------------------------------------------------
# PARTE 3: PREPARACIÓN DE DATOS Y BUCLE DE ENTRENAMIENTO
#---------------------------------------------------
def main():
    print("Iniciando... Buscando imágenes de malware...")
    print(f"Usando {NUM_WORKERS} hilos (workers) para la carga de datos.")
    
    # 1. Cargar rutas de archivos y etiquetas
    # Asume que DATA_PATH tiene subcarpetas por familia:
    # .../malvis_malimg/Adialer.C/
    # .../malvis_malimg/Agent.FYI/
    # ...
    all_image_paths = []
    all_labels = []
    
    # Crear un mapa de familia -> índice numérico
    try:
        family_names = sorted([d for d in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, d))])
    except FileNotFoundError:
        print(f"ERROR: Directorio no encontrado: {DATA_PATH}")
        print("Por favor, edita la variable 'DATA_PATH' en el script.")
        return

    label_map = {name: i for i, name in enumerate(family_names)}
    num_classes = len(family_names)

    if num_classes == 0:
        print(f"ERROR: No se encontraron subdirectorios en {DATA_PATH}")
        print("Asegúrate de que la ruta sea correcta y contenga carpetas por familia.")
        return

    print(f"Encontradas {num_classes} familias de malware.")

    for family, label_idx in label_map.items():
        # Asume imágenes .png, cambia a .jpg o .bmp si es necesario
        paths = glob.glob(os.path.join(DATA_PATH, family, "*.png")) 
        all_image_paths.extend(paths)
        all_labels.extend([label_idx] * len(paths))
        
    print(f"Total de {len(all_image_paths)} imágenes encontradas.")
    
    # NOTA: ¡En un proyecto real, aquí deberías usar
    #       sklearn.model_selection.train_test_split para
    #       dividir en conjuntos de entrenamiento y validación!
    train_paths = all_image_paths
    train_labels = all_labels

    # 2. Configurar Modelo, Pérdida y Optimizador
    # Mover el modelo a la GPU si está disponible
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Entrenando en dispositivo: {device}")
    
    model = SimpleMalwareCNN(num_classes=num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 3. Bucle de Entrenamiento
    print("--- Iniciando Entrenamiento ---")
    
    for epoch in range(NUM_EPOCHS):
        epoch_start_time = time.monotonic()
        total_loss = 0
        total_correct = 0
        total_samples = 0
        
        # ¡Usamos nuestro cargador de datos NOGIL!
        loader = nogil_threaded_loader(train_paths, train_labels, BATCH_SIZE)
        
        for i, (images, labels) in enumerate(loader):
            # Mover datos a la GPU
            images = images.to(device)
            labels = labels.to(device)
            
            # Forward pass
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            # Backward pass y optimización
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            # Estadísticas
            total_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_correct += (predicted == labels).sum().item()
            total_samples += labels.size(0)

            # Imprimir progreso del lote
            if (i + 1) % 20 == 0:
                print(f"Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{i+1}], "
                      f"Loss Parcial: {loss.item():.4f}")

        epoch_end_time = time.monotonic()
        
        # Asegurarse de no dividir por cero si no hubo lotes
        if total_samples > 0:
            avg_loss = total_loss / (i + 1)
            accuracy = 100 * total_correct / total_samples
            
            print("="*60)
            print(f"FIN DE EPOCH [{epoch+1}/{NUM_EPOCHS}]")
            print(f"  Duración: {epoch_end_time - epoch_start_time:.2f}s")
            print(f"  Loss Promedio: {avg_loss:.4f}")
            print(f"  Accuracy: {accuracy:.2f}% ({total_correct}/{total_samples})")
            print("="*60)
        else:
            print(f"Epoch [{epoch+1}/{NUM_EPOCHS}] - No se procesaron datos.")

    print("--- Entrenamiento Completado ---")

if __name__ == "__main__":
    # Comprobación rápida de nogil
    if sys.version_info >= (3, 13) and hasattr(sys, '_is_gil_enabled'):
        if not sys._is_gil_enabled():
            print("✅ Confirmado: Ejecutando en modo NOGIL.")
        else:
            print("⚠️ Advertencia: El GIL está HABILITADO. La carga con hilos será lenta.")
    else:
        print("⚠️ Advertencia: Versión de Python < 3.13 o sys._is_gil_enabled no encontrado.")
        
    main()